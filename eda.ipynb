{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3785171d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' from 'c:\\Users\\Gustavo_\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\__init__.py' has no attribute '_pandas_datetime_CAPI' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m  \u001b[38;5;66;03m# Import the pandas library for data manipulation and analysis\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gustavo_\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\__init__.py:62\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     63\u001b[39m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[32m     64\u001b[39m     ArrowDtype,\n\u001b[32m     65\u001b[39m     Int8Dtype,\n\u001b[32m     66\u001b[39m     Int16Dtype,\n\u001b[32m     67\u001b[39m     Int32Dtype,\n\u001b[32m     68\u001b[39m     Int64Dtype,\n\u001b[32m     69\u001b[39m     UInt8Dtype,\n\u001b[32m     70\u001b[39m     UInt16Dtype,\n\u001b[32m     71\u001b[39m     UInt32Dtype,\n\u001b[32m     72\u001b[39m     UInt64Dtype,\n\u001b[32m     73\u001b[39m     Float32Dtype,\n\u001b[32m     74\u001b[39m     Float64Dtype,\n\u001b[32m     75\u001b[39m     CategoricalDtype,\n\u001b[32m     76\u001b[39m     PeriodDtype,\n\u001b[32m     77\u001b[39m     IntervalDtype,\n\u001b[32m     78\u001b[39m     DatetimeTZDtype,\n\u001b[32m     79\u001b[39m     StringDtype,\n\u001b[32m     80\u001b[39m     BooleanDtype,\n\u001b[32m     81\u001b[39m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[32m     82\u001b[39m     NA,\n\u001b[32m     83\u001b[39m     isna,\n\u001b[32m     84\u001b[39m     isnull,\n\u001b[32m     85\u001b[39m     notna,\n\u001b[32m     86\u001b[39m     notnull,\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[32m     88\u001b[39m     Index,\n\u001b[32m     89\u001b[39m     CategoricalIndex,\n\u001b[32m     90\u001b[39m     RangeIndex,\n\u001b[32m     91\u001b[39m     MultiIndex,\n\u001b[32m     92\u001b[39m     IntervalIndex,\n\u001b[32m     93\u001b[39m     TimedeltaIndex,\n\u001b[32m     94\u001b[39m     DatetimeIndex,\n\u001b[32m     95\u001b[39m     PeriodIndex,\n\u001b[32m     96\u001b[39m     IndexSlice,\n\u001b[32m     97\u001b[39m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[32m     98\u001b[39m     NaT,\n\u001b[32m     99\u001b[39m     Period,\n\u001b[32m    100\u001b[39m     period_range,\n\u001b[32m    101\u001b[39m     Timedelta,\n\u001b[32m    102\u001b[39m     timedelta_range,\n\u001b[32m    103\u001b[39m     Timestamp,\n\u001b[32m    104\u001b[39m     date_range,\n\u001b[32m    105\u001b[39m     bdate_range,\n\u001b[32m    106\u001b[39m     Interval,\n\u001b[32m    107\u001b[39m     interval_range,\n\u001b[32m    108\u001b[39m     DateOffset,\n\u001b[32m    109\u001b[39m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[32m    110\u001b[39m     to_numeric,\n\u001b[32m    111\u001b[39m     to_datetime,\n\u001b[32m    112\u001b[39m     to_timedelta,\n\u001b[32m    113\u001b[39m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[32m    114\u001b[39m     Flags,\n\u001b[32m    115\u001b[39m     Grouper,\n\u001b[32m    116\u001b[39m     factorize,\n\u001b[32m    117\u001b[39m     unique,\n\u001b[32m    118\u001b[39m     value_counts,\n\u001b[32m    119\u001b[39m     NamedAgg,\n\u001b[32m    120\u001b[39m     array,\n\u001b[32m    121\u001b[39m     Categorical,\n\u001b[32m    122\u001b[39m     set_eng_float_format,\n\u001b[32m    123\u001b[39m     Series,\n\u001b[32m    124\u001b[39m     DataFrame,\n\u001b[32m    125\u001b[39m )\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtseries\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gustavo_\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\api.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     NaT,\n\u001b[32m      3\u001b[39m     Period,\n\u001b[32m      4\u001b[39m     Timedelta,\n\u001b[32m      5\u001b[39m     Timestamp,\n\u001b[32m      6\u001b[39m )\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmissing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     ArrowDtype,\n\u001b[32m     11\u001b[39m     CategoricalDtype,\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     PeriodDtype,\n\u001b[32m     15\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gustavo_\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\_libs\\__init__.py:18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterval\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtslibs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     20\u001b[39m     NaT,\n\u001b[32m     21\u001b[39m     NaTType,\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m     iNaT,\n\u001b[32m     27\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32minterval.pyx:1\u001b[39m, in \u001b[36minit pandas._libs.interval\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mhashtable.pyx:1\u001b[39m, in \u001b[36minit pandas._libs.hashtable\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mmissing.pyx:1\u001b[39m, in \u001b[36minit pandas._libs.missing\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gustavo_\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\_libs\\tslibs\\__init__.py:39\u001b[39m\n\u001b[32m      1\u001b[39m __all__ = [\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdtypes\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlocalize_pydatetime\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mis_supported_dtype\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     37\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtslibs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dtypes  \u001b[38;5;66;03m# pylint: disable=import-self\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtslibs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m localize_pydatetime\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_libs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtslibs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     42\u001b[39m     Resolution,\n\u001b[32m     43\u001b[39m     periods_per_day,\n\u001b[32m     44\u001b[39m     periods_per_second,\n\u001b[32m     45\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mdtypes.pyx:155\u001b[39m, in \u001b[36minit pandas._libs.tslibs.dtypes\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m: partially initialized module 'pandas' from 'c:\\Users\\Gustavo_\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\__init__.py' has no attribute '_pandas_datetime_CAPI' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # Import the pandas library for data manipulation and analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aca2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv ('train.csv') # Load the dataset into a pandas dataframe\n",
    "df.info() # Display information about the dataframe, including data types and non-null counts\n",
    "df.isnull().sum() # Check for missing values in each column of the dataframe\n",
    "df.dropna( inplace=True) # Drop columns with any missing values\n",
    "\n",
    "df.head(10) # Display the first 10 rows of the dataframe\n",
    "colunas_numericas = df.select_dtypes(include=['int64', 'float64']).columns # Select columns with numeric data types\n",
    "print(\"colunas numericas: \\n\", colunas_numericas)\n",
    "\n",
    "colunas_categoricas = df.select_dtypes(include=['object']).columns # Select columns with categorical data types\n",
    "print(\"\\ncolunas categoricas: \\n\", colunas_categoricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7018f87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns # Import the seaborn library for data visualization\n",
    "import matplotlib.pyplot as plt # Import the matplotlib library for plotting\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "df.dtypes [df.dtypes == 'object'] # Display the data types of columns that are of type 'object' (categorical)\n",
    "df_numerico = df.select_dtypes(include=['int64', 'float64']) # Create a new dataframe with only numeric columns\n",
    "\n",
    "correlacao = df_numerico.corr() # Calculate the correlation matrix for the numeric columns in the dataframe\n",
    "\n",
    "plt.figure(figsize=(15, 8)) # Set the figure size for the plot\n",
    "sns.heatmap(correlacao [['SalePrice']].sort_values(by='SalePrice', ascending=False), annot=True, cmap='coolwarm') # Create a heatmap to visualize the correlation between 'SalePrice' and other numeric columns\n",
    "plt.title('Mapa de calor da correlação') # Set the title of the heatmap\n",
    "plt.show() # Display the heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befb23e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma para ver a distribuição dos preços\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df['SalePrice'], kde=True, color='blue')\n",
    "plt.title('Distribuição dos Preços das Casas')\n",
    "plt.xlabel('Preço')\n",
    "plt.ylabel('Frequência')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e7a862",
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_nnulos = df.isnull().sum().sort_values(ascending=False) # Check for missing values in the dataframe and sort them in descending order\n",
    "valores_nnulos = valores_nnulos[valores_nnulos > 0] # Filter the dataframe to keep only columns with missing values\n",
    "print(valores_nnulos) # Display the columns with missing values and their countsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5b858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PoolQC'].fillna('No Pool', inplace=True) # Fill missing values in the 'poolQC' column with 'No Pool'\n",
    "df['MiscFeature'].fillna('None', inplace=True) # Fill missing values in the 'MiscFeature' column with None\n",
    "df['Alley'].fillna('No Alley', inplace=True) # Fill missing values in the 'Alley' column with 'No Alley'\n",
    "df['Fence'].fillna('No Fence', inplace=True) # Fill missing values in the 'Fence' column with 'No Fence'\n",
    "df['MasVnrType'].fillna('none', inplace=True) # Fill missing values in the 'MasVnrType' column with 'none'\n",
    "df['FireplaceQu'].fillna('No Fireplace', inplace=True) # Fill missing values in the 'FireplaceQu' column with 'No Fireplace'\n",
    "\n",
    "df['GarageQual'].fillna('No Garage', inplace=True) # Fill missing values in the 'GarageQual' column with 'No Garage'\n",
    "df['GarageFinish'].fillna('No Garage', inplace=True) # Fill missing values in the 'GarageFinish' column with 'No Garage'\n",
    "df['GarageType'].fillna('No garage',inplace=True) # Fill missing values in the 'GarageType' column with 'No garage'\n",
    "df['GarageCond'].fillna('No Garage', inplace=True) # Fill missing values in the 'GarageCond' column with 'No Garage'\n",
    "\n",
    "\n",
    "df['BsmtFinType2'].fillna('No Basement', inplace=True) # Fill missing values in the 'BsmtFinType2' column with 'No Basement'\n",
    "df['BsmtExposure'].fillna('No Basement', inplace=True) # Fill missing values in the 'BsmtExposure' column with 'No Basement'\n",
    "df['BsmtCond'].fillna('No Basement', inplace=True) # Fill missing values in the 'BsmtCond' column with 'No Basement'    \n",
    "df['BsmtQual'].fillna('No Basement', inplace=True) # Fill missing values in the 'BsmtQual' column with 'No Basement'\n",
    "df['BsmtFinType1'].fillna('No Basement', inplace=True) # Fill missing values in the 'BsmtFinType1' column with 'No Basement'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c0ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LotFrontage'].fillna(df['LotFrontage'].mean(), inplace=True) # Fill missing values in the 'LotFrontage' column with the mean of that column\n",
    "df['MasVnrArea'].fillna(0, inplace=True) # Fill missing values in the 'MasVnrArea' column with 0\n",
    "df['GarageYrBlt'].fillna(0, inplace=True) # Fill missing values in the 'GarageYrBlt' column with 0\n",
    "df['Electrical'].fillna(df['Electrical'].mode()[0], inplace=True) # Fill missing values in the 'Electrical' column with the mode of that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce19407",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222fd683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # Import the matplotlib library for plotting\n",
    "import seaborn as sns # Import the seaborn library for data visualization\n",
    "\n",
    "variaveis_importantes  = ['GrLivArea', 'TotalBsmtSF', 'GarageArea', '1stFlrSF', 'LotFrontage']  # List of important variables to analyze\n",
    "\n",
    "plt.figure(figsize=(15, 8)) # Set the figure size for the plot\n",
    "for i, coluna in enumerate(variaveis_importantes ,1): # Loop through the important variables and their indices\n",
    "    plt.subplot (2, 3, i) # Create a subplot for each variable\n",
    "    sns.boxplot(x=df[coluna])\n",
    "    plt.title(f'boxplot de {coluna}')   # Set the title of the boxplot\n",
    "plt.tight_layout() # Adjust the layout of the subplots\n",
    "plt.show() # Display the boxplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b5666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers= df [(df ['GrLivArea'] > 4000) & (df ['SalePrice'] < 300000)] # Identify outliers based on the 'GrLivArea' and 'SalePrice' columns\n",
    "print (\"Outliers: \\n\") # Display the identified outliers\n",
    "display(outliers) # Display the outliers in a more readable format\n",
    "\n",
    "plt.figure(figsize=(15, 8)) # Set the figure size for the plot\n",
    "sns.scatterplot(data=df, x = 'GrLivArea', y='SalePrice', color = 'blue', label = 'Normal') # Plot the normal data points\n",
    "sns.scatterplot(data=outliers, x = 'GrLivArea', y='SalePrice', color = 'red', label = 'Outliers') # Plot the outliers in a different color\n",
    "plt.title('GrLivArea vs SalePrice') # Set the title of the scatter plot\n",
    "plt.show() # Display the scatter plot\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69741fd",
   "metadata": {},
   "source": [
    "\n",
    "**Aqui eu quis ver os outliers em todas as colunas influentes para ver o quanto outliers estao sendo relevantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9a21f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns  # Import the seaborn library for data visualization\n",
    "import matplotlib.pyplot as plt  # Import the matplotlib library for plotting\n",
    "\n",
    "# Lista das colunas que queremos analisar\n",
    "colunas1 = ['GrLivArea', 'TotalBsmtSF', 'GarageArea', '1stFlrSF', 'LotFrontage', \n",
    "            'OverallQual', 'GarageCars', 'FullBath', 'YearBuilt', 'TotRmsAbvGrd']\n",
    "\n",
    "# Definindo o tamanho da figura e a quantidade de linhas e colunas\n",
    "plt.figure(figsize=(15, 20)) \n",
    "\n",
    "# Loop para criar os subplots\n",
    "for i, coluna in enumerate(colunas1, 1):\n",
    "    plt.subplot(5, 2, i)  # Organiza em 5 linhas e 2 colunas\n",
    "    \n",
    "    # Gráfico de dispersão dos dados normais\n",
    "    sns.scatterplot(data=df, x=coluna, y='SalePrice', color='blue', label='Normal')\n",
    "    \n",
    "    # Identificação dos outliers com base no 95º percentil\n",
    "    outliers_coluna = df[(df[coluna] > df[coluna].quantile(0.95)) & (df['SalePrice'] < 300000)]\n",
    "    \n",
    "    # Gráfico de dispersão dos outliers\n",
    "    sns.scatterplot(data=outliers_coluna, x=coluna, y='SalePrice', color='red', label='Outliers')\n",
    "    \n",
    "    # Título para cada gráfico\n",
    "    plt.title(f'Outliers em {coluna}')\n",
    "\n",
    "# Ajusta o layout para não sobrepor os gráficos\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "display(outliers) # Display the outliers in a more readable format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316c328c",
   "metadata": {},
   "source": [
    "\n",
    "**Agora quero testar diferentes percentis para ver a diferenca de um para o outro para sabermos com qual vamos trabalhar**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f83a1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "percentis = [0.90, 0.95, 0.99] # Define the percentiles to be used for outlier detection\n",
    "coluna2 = 'GrLivArea' # Define the column to be analyzed for outliers\n",
    "\n",
    "plt.figure(figsize=(15, 8)) # Set the figure size for the plot\n",
    "\n",
    "for i, perc in enumerate(percentis, 1): # Loop through the percentiles and their indices\n",
    "    plt.subplot(1, len(percentis), i) # Create a subplot for each percentile\n",
    "    outliers = df[df[coluna] > df[coluna].quantile(perc)] # Identify outliers based on the specified percentile\n",
    "    sns.scatterplot(data=df, x=coluna2, y='SalePrice', color='blue', label='Normal') # Plot the normal data points\n",
    "    sns.scatterplot(data=outliers, x=coluna2, y='SalePrice', color='red', label='Outliers') # Plot the outliers in a different color\n",
    "    plt.title(f'Outliers em {coluna2} - Percentil {perc}') # Set the title of the scatter plot\n",
    "plt.tight_layout() # Adjust the layout of the subplots\n",
    "plt.show() # Display the scatter plot\n",
    "\n",
    "display(outliers) # Display the outliers in a more readable format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8121988d",
   "metadata": {},
   "source": [
    "\n",
    "**Pude observar que 0.95 e um otimo meio termo para continuar para a remocao dos mesmos outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494aabbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_categoricas = df.select_dtypes(include=['object']).columns # Select columns with categorical data types\n",
    "print(\"\\ncolunas categoricas: \\n\", colunas_categoricas) # Display the categorical columns\n",
    "# Loop through each categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba842fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_nulos_categoricos = df[colunas_categoricas].isnull().sum() # Check for missing values in the categorical columns\n",
    "print(valores_nulos_categoricos) # Display the missing values in the categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a327c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for coluna in colunas_categoricas:\n",
    "    print(f\"\\nDistribuição de {coluna}:\") # Print the distribution of each categorical column\n",
    "    display(pd.DataFrame(df[coluna].value_counts()).reset_index().rename(columns={'index': coluna, coluna: 'Contagem'})) # Display the value counts of each categorical column in a readable format\n",
    "display(df.head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfb63df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder # Import the LabelEncoder class from sklearn for encoding categorical variables\n",
    "\n",
    "\n",
    "# Identificando quais colunas são categóricas\n",
    "colunas_categoricas = df.select_dtypes(['object']).columns # Select columns with categorical data types\n",
    "\n",
    "\n",
    "# Aplicando Label Encoding para cada coluna categórica\n",
    "for coluna in colunas_categoricas:\n",
    "    if df[coluna].nunique() <= 10: # Check if the number of unique values is less than or equal to 10\n",
    "        le = LabelEncoder()\n",
    "        df[coluna]=le.fit_transform(df[coluna]) # Apply label encoding to the categorical column\n",
    "        print(f\"Coluna {coluna} transformada com Label Encoding\")\n",
    "    else:\n",
    "        df = pd.get_dummies(df, columns=[coluna], drop_first=True) # Apply one-hot encoding to the categorical column\n",
    "        print(f\"Coluna {coluna} transformada com One-Hot Encoding\")\n",
    "display(df.head(25))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f6ced7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "139da5a3",
   "metadata": {},
   "source": [
    "**⚠️ Ponto de Atenção:\n",
    "Se você usar LabelEncoder para coisas que não têm uma ordem clara (ex.: Cores, Tipos de Casa, Bairros), o modelo pode entender que \"2\" é maior que \"1\", e \"1\" é maior que \"0\", o que não é verdade nesse caso.\n",
    "Já com o One-Hot, isso não acontece, porque cada categoria é independenteeeeeeeee.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04e9025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # Import the train_test_split function from sklearn for splitting the dataset\n",
    "\n",
    "x= df.drop(columns=['SalePrice'], axis=1) # Drop the 'SalePrice' column from the dataframe to create the feature set\n",
    "y= df['SalePrice'] # Set the target variable to 'SalePrice'\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=42) # Split the dataset into training and testing sets\n",
    "print(f\"Tamanho do conjunto de treino: {x_train.shape[0]} amostras\")\n",
    "print(f\"Tamanho do teste: {x_test.shape[0]} amostras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd57fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression  # Importa o modelo de Regressão Linear\n",
    "from sklearn.ensemble import RandomForestRegressor  # Importa o modelo de Random Forest para regressão\n",
    "from sklearn.model_selection import train_test_split  # Importa a função para dividir o dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score  # Importa métricas para avaliação\n",
    "\n",
    "modelos = {\n",
    "    'Regressao Linear': LinearRegression(), # Define a dictionary of models to be used\n",
    "    'Random Forest': RandomForestRegressor(random_state=42 ), # Add Random Forest model\n",
    "}\n",
    "\n",
    "for nome, modelo in modelos.items (): # Loop through each model in the dictionary\n",
    "    modelo.fit(x_train, y_train) # Fit the model to the training data\n",
    "    y_pred = modelo.predict(x_test) # Make predictions on the test data\n",
    "\n",
    "    mae = mean_absolute_error (y_test, y_pred) # Calculate the mean absolute error\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred)) # Calculate the root mean squared error\n",
    "    r2 = r2_score (y_test, y_pred) # Calculate the R-squared score\n",
    "\n",
    "    print(f\"\\nModelo: {nome}\") # Print the name of the model\n",
    "    print(f\"- MAE (Erro Médio Absoluto): ${mae:.2f}\") # Print the mean absolute error\n",
    "    print(f\"- RMSE (Erro Quadrático Médio): ${rmse:.2f}\") # Print the root mean squared error\n",
    "    print(f\"- R² (Explicação da Variância): {r2:.4f}\") # Print the R-squared score\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8034fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interações entre features importantes\n",
    "df['Qual_x_Area'] = df['OverallQual'] * df['GrLivArea']  # Qualidade x Área\n",
    "df['Garage_x_Bsmt'] = df['GarageCars'] * df['TotalBsmtSF']  # Garagem + Porão\n",
    "\n",
    "# Área total da casa (já existente, mas crucial)\n",
    "df['TotalSF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']\n",
    "\n",
    "# Idade da casa ajustada por reformas\n",
    "df['EffectiveAge'] = df['YrSold'] - df['YearRemodAdd']  # Idade pós-reforma\n",
    "\n",
    "# Densidade de cômodos\n",
    "df['RoomDensity'] = df['TotRmsAbvGrd'] / df['GrLivArea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bc6d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo para GrLivArea\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(x=df['GrLivArea'])\n",
    "plt.title('Distribuição de GrLivArea')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57782fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=1200,  # Mais iterações\n",
    "    learning_rate=0.05,  # Taxa de aprendizado reduzida\n",
    "    max_depth=5,\n",
    "    subsample=0.8,  # Previne overfitting\n",
    "    colsample_bytree=0.8,  # Similar ao max_features\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb.fit(x_train, y_train)\n",
    "y_pred_xgb = xgb.predict(x_test)\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "print(f\"RMSE XGBoost: {rmse_xgb:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e3e43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05],  # Taxas menores para ajuste fino\n",
    "    'max_depth': [4, 5, 6],          # Testar profundidades\n",
    "    'subsample': [0.8, 0.9],         # Controle de overfitting\n",
    "    'colsample_bytree': [0.8, 0.9],  #% de features por árvore\n",
    "    'n_estimators': [800, 1000, 1200]      # Mais árvores com learning_rate baixo\n",
    "}\n",
    "\n",
    "busca_xgb = GridSearchCV(\n",
    "    XGBRegressor(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "busca_xgb.fit(x_train, y_train)\n",
    "print(f\"Melhor RMSE: {-busca_xgb.best_score_:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99e5406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
